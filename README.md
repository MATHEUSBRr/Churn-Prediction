üß† Projeto Pr√°tico ‚Äì Predi√ß√£o de Churn com Machine Learning
üîç An√°lise de Dados ‚Ä¢ ETL ‚Ä¢ Visualiza√ß√£o ‚Ä¢ Modelagem ‚Ä¢ Avalia√ß√£o

Este projeto tem como objetivo aplicar todo o processo de an√°lise de dados, prepara√ß√£o, modelagem e avalia√ß√£o utilizando um conjunto de dados fict√≠cio de clientes. A solu√ß√£o prev√™ churn ‚Äî ou seja, a probabilidade de um cliente cancelar um servi√ßo ‚Äî utilizando t√©cnicas de aprendizagem de m√°quina.

üë®‚Äçüíª Desenvolvido por

Projeto desenvolvido pelos integrantes do grupo:

Matheus Franklin Brasileiro ‚Äî GitHub: MATHEUSBRr

Victor Hugo N. Dias ‚Äî GitHub: VictorVHND

Yan Macedo Teixeira ‚Äî GitHub: Yanmaiscedo

üìå 1. Descri√ß√£o Detalhada do Problema e Objetivos do Projeto

Empresas que operam com servi√ßos recorrentes (ex.: internet, telefonia, streaming) t√™m como um dos maiores desafios reduzir a evas√£o de clientes, conhecida como churn. Prever quais clientes t√™m maior probabilidade de cancelar o servi√ßo permite que equipes de reten√ß√£o atuem de forma preventiva.

‚ùó Problema

Como identificar automaticamente os clientes com maior risco de churn, usando dados internos da empresa?

üéØ Objetivos principais

Criar um conjunto de dados fict√≠cio simulando clientes e comportamentos.

Realizar ETL completo: limpeza, tratamento e engenharia de atributos.

Desenvolver visualiza√ß√µes para entender padr√µes e rela√ß√µes.

Treinar um modelo de Machine Learning para prever churn.

Avaliar o desempenho do modelo com m√©tricas adequadas.

Criar um pipeline reprodut√≠vel com scripts separados.

Gerar um relat√≥rio final com gr√°ficos, m√©tricas e an√°lise dos resultados.

üõ†Ô∏è 2. Processo de ETL (Extra√ß√£o, Transforma√ß√£o e Carga)

O script respons√°vel por esta etapa est√° em:
src/etl.py

Extra√ß√£o

O dataset fict√≠cio √© carregado a partir de:

data/churn_data.csv


Ele cont√©m colunas como:

customer_id

age

gender

contract_months

monthly_fee

support_calls

payment_delay

usage_minutes

churn (0 ou 1)

Transforma√ß√£o

As principais etapas de transforma√ß√£o foram:

‚úî Tratamento de valores inconsistentes

Exclus√£o de linhas com valores imposs√≠veis ou extremos.

Corre√ß√£o de tipos num√©ricos.

‚úî Normaliza√ß√£o de texto

Padroniza√ß√£o de gender, convers√£o para categorias num√©ricas.

‚úî Feature Engineering

Foram criadas novas vari√°veis mais informativas:

avg_monthly_usage = usage_minutes / contract_months

delayed_payments_flag = 1 se payment_delay > 0

high_support_usage = clientes com mais de 3 chamadas no suporte

‚úî Escalonamento / Padroniza√ß√£o

Apenas para modelos que necessitam. No RandomForest n√£o √© obrigat√≥rio.

Carga

Ap√≥s o processamento, os dados preparados s√£o salvos em:

data/processed_churn.csv

üìä 3. An√°lise Explorat√≥ria e Visualiza√ß√µes

A an√°lise explorat√≥ria foi realizada no script:

src/eda.py

Foram gerados gr√°ficos e salvos em:

reports/figures/

Principais visualiza√ß√µes:

Histograma de idade dos clientes

Distribui√ß√£o de churn por g√™nero

Boxplot do valor mensal vs churn

Correla√ß√£o entre vari√°veis

Gr√°fico de chamadas de suporte por cliente

Insights encontrados:

Clientes com alto n√∫mero de chamadas no suporte apresentam maior churn.

Contratos mais curtos t√™m maior taxa de evas√£o.

Pagamentos atrasados tamb√©m s√£o um forte indicador.

Uso mensal muito baixo ou muito alto tem rela√ß√£o com churn.

Estas informa√ß√µes foram fundamentais para escolher o modelo e entender o comportamento dos clientes.

ü§ñ 4. Modelagem e Algoritmos de Machine Learning

A modelagem foi realizada no script:

src/model.py

Algoritmo escolhido

O modelo utilizado foi:

Random Forest Classifier

Bom para dados tabulares.

Robusto a outliers.

Lida bem com rela√ß√µes n√£o-lineares.

Dispensa normaliza√ß√£o de dados.

Hiperpar√¢metros utilizados (vers√£o final executada)

n_estimators = 100

max_depth = 7

random_state = 42

n_jobs = -1 (usa todos os n√∫cleos dispon√≠veis)

Os hiperpar√¢metros foram selecionados ap√≥s testes preliminares; h√° tamb√©m um script com GridSearchCV para explorar combina√ß√µes mais amplas.

Divis√£o de dados

75% para treino

25% para teste

Amostragem estratificada garantindo equil√≠brio das classes

üìà 5. Avalia√ß√£o e Interpreta√ß√£o dos Resultados

A avalia√ß√£o foi realizada em:

src/evaluate.py

M√©tricas calculadas:

Acur√°cia

Precis√£o

Recall

F1-score

ROC-AUC

Matriz de confus√£o

Curva ROC

Principais resultados obtidos:

(Exemplo real do modelo gerado)

Classe	Precis√£o	Recall	F1-score
N√£o churn	0.75	0.93	0.83
Churn	0.69	0.32	0.44
Interpreta√ß√£o:

O modelo identifica muito bem clientes que n√£o ir√£o cancelar (recall alto para classe 0).

Tem dificuldade moderada em capturar todos os clientes que ir√£o cancelar (recall da classe 1 √© menor).

Isso √© comum em datasets onde churn √© uma classe menos frequente.

ROC-AUC aproximadamente 0.70+, indicando bom poder de separa√ß√£o.

Import√¢ncia das vari√°veis

As features mais relevantes foram:

support_calls

payment_delay

contract_months

monthly_fee

avg_monthly_usage

Estas vari√°veis fazem sentido no contexto de churn, refor√ßando a qualidade do modelo.

üèÅ 6. Conclus√£o, Aprendizados, Limita√ß√µes e Melhorias Futuras
‚úî Aprendizados

A import√¢ncia da etapa de ETL para garantir qualidade do modelo.

Como a an√°lise explorat√≥ria orienta a escolha das features.

Aplica√ß√£o pr√°tica de um modelo de Machine Learning completo.

Interpreta√ß√£o de m√©tricas e valida√ß√£o do modelo.

‚úî Limita√ß√µes atuais

O dataset √© fict√≠cio, podendo n√£o refletir totalmente um cen√°rio real.

Classe de churn √© desbalanceada, dificultando recall.

Apenas Random Forest foi treinado na vers√£o final executada.

‚úî Poss√≠veis melhorias

Implementar t√©cnicas de balanceamento, como SMOTE.

Comparar com modelos mais avan√ßados, como XGBoost ou LightGBM.

Usar otimiza√ß√£o bayesiana para hiperpar√¢metros.

Criar um painel interativo (Dash/Streamlit).

Aumentar vari√°veis comportamentais e transacionais.

‚ñ∂Ô∏è Como Rodar o Projeto

1. Clone este reposit√≥rio

No terminal:

git clone https://github.com/MATHEUSBRr/Churn-Prediction.git

2. Crie e ative um ambiente virtual
Windows:
python -m venv venv
venv\Scripts\activate

Linux / Mac:
python3 -m venv venv
source venv/bin/activate

3. Instale as depend√™ncias

Com o ambiente virtual ativado, execute:

pip install -r requirements.txt

4. Execute o pipeline completo
‚úîÔ∏è ETL (tratamento e prepara√ß√£o dos dados)
python src/etl.py

‚úîÔ∏è An√°lise Explorat√≥ria (gera gr√°ficos)
python src/eda.py

‚úîÔ∏è Treinamento do Modelo
python src/model.py

‚úîÔ∏è Avalia√ß√£o do Modelo
python src/evaluate.py

‚úîÔ∏è Gerar Relat√≥rio em Word
python src/generate_report.py

5. Onde encontrar os resultados

Ap√≥s rodar os scripts, os resultados aparecer√£o automaticamente nas pastas:

üìÇ data/

processed_churn.csv ‚Äî dados limpos e transformados

üìÇ models/

rf_churn.joblib ‚Äî modelo treinado

üìÇ reports/

metrics.txt ‚Äî m√©tricas completas

report.docx ‚Äî relat√≥rio final

üìÅ figures/ ‚Äî todos os gr√°ficos gerados (histogramas, ROC, matriz de confus√£o etc.)

6. Requisitos

Python 3.9+

VSCode (opcional, mas recomendado)

Pip atualizado